{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "import your train dataset ....                \n",
        "folder structure                   \n",
        " data/        \n",
        " |-positive ( your images)           \n",
        " |-anchor ( your anchoe images - you....)          \n",
        " |-negative ( LFW images or any other images than you )"
      ],
      "metadata": {
        "id": "r33gczVqQguv"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import shutil\n",
        "\n",
        "zip_path = \"data.zip\"\n",
        "extract_to = \"data\"\n",
        "\n",
        "shutil.unpack_archive(zip_path, extract_to)\n",
        "print(\"Unzipped successfully\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "N_U1D6U067_Y",
        "outputId": "b040f0a7-e478-434e-9b2f-b528b19046a9"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Unzipped successfully\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import cv2\n",
        "import numpy as np"
      ],
      "metadata": {
        "id": "Sbuuuh417yQt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "preprocess the image to fit our embedding layer\n"
      ],
      "metadata": {
        "id": "WAWXPpD4SI-e"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def preprocess_image(path):\n",
        "    img = tf.io.read_file(path)\n",
        "    img = tf.image.decode_jpeg(img, channels=3)\n",
        "    img = tf.image.resize(img, (100,100))\n",
        "    img = tf.cast(img, tf.float32) / 255.0\n",
        "    return img\n"
      ],
      "metadata": {
        "id": "ePOM3nwu8Yvx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "the embedding layer where we transform the image to a numerical value (tf tensor)\n"
      ],
      "metadata": {
        "id": "xJNVbKbWSOpw"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "WetEAoVy5DRK"
      },
      "outputs": [],
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow.keras.layers import (\n",
        "    Conv2D, MaxPooling2D,\n",
        "    GlobalAveragePooling2D, Dense, Input\n",
        ")\n",
        "from tensorflow.keras.models import Model\n",
        "\n",
        "class L2Normalize(tf.keras.layers.Layer):\n",
        "    def call(self, x):\n",
        "        return tf.math.l2_normalize(x, axis=1)\n",
        "\n",
        "def make_embedding():\n",
        "    inp = Input(shape=(100,100,3), name=\"input_image\")\n",
        "\n",
        "    # Convolutional base\n",
        "    x = Conv2D(32, (7,7), activation='relu', padding='same')(inp)\n",
        "    x = MaxPooling2D((2,2))(x)\n",
        "\n",
        "    x = Conv2D(64, (5,5), activation='relu', padding='same')(x)\n",
        "    x = MaxPooling2D((2,2))(x)\n",
        "\n",
        "    x = Conv2D(128, (3,3), activation='relu', padding='same')(x)\n",
        "    x = GlobalAveragePooling2D()(x)\n",
        "\n",
        "    # Project to embedding space\n",
        "    x = Dense(128, activation='relu')(x)\n",
        "    x = L2Normalize()(x)\n",
        "\n",
        "    return Model(inputs=inp, outputs=x, name=\"embedding\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "function to find distance between the images ( eucilidian distance )"
      ],
      "metadata": {
        "id": "X9SvUrJqSaSa"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class L2Distance(tf.keras.layers.Layer):\n",
        "    def call(self, inputs):\n",
        "        e1, e2 = inputs\n",
        "        return tf.norm(e1 - e2, axis=1, keepdims=True)\n"
      ],
      "metadata": {
        "id": "09cTQGXf5ktu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def make_siamese_model():\n",
        "    embedding = make_embedding()\n",
        "\n",
        "    img1 = Input(shape=(100,100,3), name=\"img1\")\n",
        "    img2 = Input(shape=(100,100,3), name=\"img2\")\n",
        "\n",
        "    e1 = embedding(img1)\n",
        "    e2 = embedding(img2)\n",
        "\n",
        "    dist = L2Distance()([e1, e2])\n",
        "\n",
        "    return Model([img1, img2], dist, name=\"siamese\")\n",
        "\n",
        "siamese_model=make_siamese_model()"
      ],
      "metadata": {
        "id": "wQEhl-Bw5nuT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "loss function\n",
        "   loss is less for same image and high for different img\n",
        "   "
      ],
      "metadata": {
        "id": "GP936F_qSjnw"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def contrastive_loss(y_true, d, margin=1.0):\n",
        "    y_true = tf.cast(y_true, tf.float32)\n",
        "    pos_loss = y_true * tf.square(d)\n",
        "    neg_loss = (1 - y_true) * tf.square(tf.maximum(margin - d, 0))\n",
        "    return tf.reduce_mean(pos_loss + neg_loss)\n"
      ],
      "metadata": {
        "id": "HAzzmiI35rAu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "train and weight update function\n"
      ],
      "metadata": {
        "id": "VZkRZLFoUnmE"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "optimizer = tf.keras.optimizers.Adam(1e-4)\n",
        "\n",
        "@tf.function\n",
        "def train_step(batch):\n",
        "    img1, img2, labels = batch\n",
        "\n",
        "    with tf.GradientTape() as tape:\n",
        "        d = siamese_model([img1, img2])\n",
        "        loss = contrastive_loss(labels, d)\n",
        "\n",
        "    grads = tape.gradient(loss, siamese_model.trainable_variables)\n",
        "    optimizer.apply_gradients(zip(grads, siamese_model.trainable_variables))\n",
        "\n",
        "    return loss\n",
        "\n"
      ],
      "metadata": {
        "id": "fQlB0A845u0l"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "train dataset and test dataset creation"
      ],
      "metadata": {
        "id": "LIQC2wOlU0bF"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "pos_path=os.path.join('data',\"data\",'positive')\n",
        "\n",
        "neg_path=os.path.join('data',\"data\",'negative')\n",
        "anc_path=os.path.join('data',\"data\",'anchor')\n",
        "\n"
      ],
      "metadata": {
        "id": "lxJ9YLKW6YIX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "anchor_imgs=tf.data.Dataset.list_files(anc_path+'/*.jpg')\n",
        "positive_imgs=tf.data.Dataset.list_files(pos_path+'/*.jpg')\n",
        "negative_imgs=tf.data.Dataset.list_files(neg_path+'/*.jpg')"
      ],
      "metadata": {
        "id": "0oW1YT2P7L8B"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def preprocessing_twin(anch_file,test_file,num):\n",
        "    return (preprocess_image(anch_file),preprocess_image(test_file),num)"
      ],
      "metadata": {
        "id": "AW5moPaq9G8q"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "anchor=anchor_imgs.take(100)\n",
        "positive=positive_imgs.take(100)\n",
        "negative=negative_imgs.take(100)"
      ],
      "metadata": {
        "id": "oySU0PXo7O3Q"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "positives=tf.data.Dataset.zip((anchor,positive,tf.data.Dataset.from_tensor_slices(tf.ones(len(anchor)))))\n",
        "negatives=tf.data.Dataset.zip((anchor,negative,tf.data.Dataset.from_tensor_slices(tf.zeros(len(anchor)))))\n",
        "print(len(negatives))\n",
        "data=positives.concatenate(negatives)\n",
        "len(data)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lYX8fkeV76LS",
        "outputId": "6cba59cf-4891-4cd6-bbb4-52bf2d51d9d1"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "100\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "200"
            ]
          },
          "metadata": {},
          "execution_count": 16
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "data=data.map(preprocessing_twin)\n",
        "data=data.cache()\n",
        "data=data.shuffle(buffer_size=1024)"
      ],
      "metadata": {
        "id": "aMOHd__q8ATh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_data=data.take(round(len(data)*.7))\n",
        "print(len(train_data))\n",
        "train_data=train_data.batch(16)\n",
        "train_data=train_data.prefetch(8)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "A4ohNQtL_yz_",
        "outputId": "5faa104d-a1bf-4c95-c6ab-14820f6ccf32"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "140\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "test_data=data.skip(round(len(data)*.7))\n",
        "test_data=data.take(round(len(data)*.3))\n",
        "print(len(test_data))\n",
        "test_data=test_data.batch(16)\n",
        "test_data=test_data.prefetch(8)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OCkc2ZnR_059",
        "outputId": "74c2ec56-522c-49f3-9619-fc7cee8cea11"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "60\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "model training"
      ],
      "metadata": {
        "id": "LoldYGGTU_UZ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "EPOCHS = 10\n",
        "STEPS_PER_EPOCH = 100\n",
        "\n",
        "for epoch in range(EPOCHS):\n",
        "    print(f\"\\nEpoch {epoch+1}/{EPOCHS}\")\n",
        "\n",
        "    for step, batch in enumerate(train_data):\n",
        "\n",
        "        loss = train_step(batch)\n",
        "\n",
        "        if step % 20 == 0:\n",
        "            print(f\"Step {step}, Loss: {loss.numpy():.4f}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pX48Waqm8FmJ",
        "outputId": "dd6b2821-a25c-42b2-b6ae-c93e8b7351ed"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Epoch 1/10\n",
            "Step 0, Loss: 0.5669\n",
            "\n",
            "Epoch 2/10\n",
            "Step 0, Loss: 0.3813\n",
            "\n",
            "Epoch 3/10\n",
            "Step 0, Loss: 0.2618\n",
            "\n",
            "Epoch 4/10\n",
            "Step 0, Loss: 0.2884\n",
            "\n",
            "Epoch 5/10\n",
            "Step 0, Loss: 0.2453\n",
            "\n",
            "Epoch 6/10\n",
            "Step 0, Loss: 0.2878\n",
            "\n",
            "Epoch 7/10\n",
            "Step 0, Loss: 0.2895\n",
            "\n",
            "Epoch 8/10\n",
            "Step 0, Loss: 0.2935\n",
            "\n",
            "Epoch 9/10\n",
            "Step 0, Loss: 0.2827\n",
            "\n",
            "Epoch 10/10\n",
            "Step 0, Loss: 0.2672\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "testing phase\n"
      ],
      "metadata": {
        "id": "7LXD-QFvVi5c"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "as i dont have a proper web cam i am upload a floder with refernce images ( me ) and a test input folder ( photos of me and others ) if u dont have a proper web cam i suggest you do this"
      ],
      "metadata": {
        "id": "WXqe7edNVCJN"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "\n",
        "def load_reference_embeddings(embedding_model, ref_folder):\n",
        "    ref_embeddings = []\n",
        "\n",
        "    for file in os.listdir(ref_folder):\n",
        "        path = os.path.join(ref_folder, file)\n",
        "        emb = embedding_model(preprocess_image_verify(path), training=False)\n",
        "        ref_embeddings.append(emb)\n",
        "\n",
        "    return ref_embeddings\n"
      ],
      "metadata": {
        "id": "pnBKS3JS-NWc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "verification function"
      ],
      "metadata": {
        "id": "cOIjWDEdVV2R"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "\n",
        "def verify_image(embedding_model, ref_embeddings, img_path, threshold=0.6):\n",
        "    test_emb = embedding_model(preprocess_image(img_path), training=False)\n",
        "\n",
        "    distances = [\n",
        "        tf.norm(test_emb - ref_emb, axis=1).numpy()[0]\n",
        "        for ref_emb in ref_embeddings\n",
        "    ]\n",
        "\n",
        "    mean_distance = np.mean(distances)\n",
        "\n",
        "    return mean_distance, mean_distance < threshold\n"
      ],
      "metadata": {
        "id": "_nsm11gXDCcz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import traceback\n",
        "\n",
        "def verify_folder(embedding_model, ref_embeddings, folder, threshold=0.6):\n",
        "    for file in os.listdir(folder):\n",
        "        path = os.path.join(folder, file)\n",
        "        print(f\"\\nProcessing: {file}\")\n",
        "\n",
        "        try:\n",
        "            img = preprocess_image_verify(path)\n",
        "            print(\"  preprocess OK, shape:\", img.shape)\n",
        "\n",
        "            test_emb = embedding_model(img, training=False)\n",
        "            print(\"  embedding OK, shape:\", test_emb.shape)\n",
        "\n",
        "            distances = []\n",
        "            for ref_emb in ref_embeddings:\n",
        "                d = tf.norm(test_emb - ref_emb, axis=1)\n",
        "                distances.append(float(d.numpy()[0]))\n",
        "\n",
        "            mean_distance = sum(distances) / len(distances)\n",
        "            print(\"  mean distance:\", mean_distance)\n",
        "\n",
        "            print(\"  RESULT:\", \"YOU\" if mean_distance < threshold else \"NOT YOU\")\n",
        "\n",
        "        except Exception as e:\n",
        "            print(\"  ❌ ERROR:\")\n",
        "            traceback.print_exc()\n"
      ],
      "metadata": {
        "id": "P1ne6QcSC9oQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def preprocess_image_verify(path):\n",
        "    img = preprocess_image(path)      # reuse training logic\n",
        "    return tf.expand_dims(img, axis=0)\n"
      ],
      "metadata": {
        "id": "t1B7a3ZOEhbx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "fucntion calling and seeing if our model works properly"
      ],
      "metadata": {
        "id": "_tvxPtQsVb7N"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "reference -> your images         \n",
        "input_images -> test images"
      ],
      "metadata": {
        "id": "388GLLzBVpY7"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "embedding_model = make_embedding()  # or load it\n",
        "ref_embeddings = load_reference_embeddings(\n",
        "    embedding_model,\n",
        "    \"reference/reference\"\n",
        ")\n",
        "\n",
        "results = verify_folder(\n",
        "    embedding_model,\n",
        "    ref_embeddings,\n",
        "    \"/content/input_images/input_images\",\n",
        "    threshold=0.05\n",
        ")\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "vWNROa2JDbdm",
        "outputId": "0e5ea7be-3d9f-45d9-cd30-cbb10b7e7772"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Processing: licensed-image.jpg\n",
            "  preprocess OK, shape: (1, 100, 100, 3)\n",
            "  embedding OK, shape: (1, 128)\n",
            "  mean distance: 0.10020907750974099\n",
            "  RESULT: NOT YOU\n",
            "\n",
            "Processing: Legends-Profile_Eric-Cantona1523462164078.jpg\n",
            "  preprocess OK, shape: (1, 100, 100, 3)\n",
            "  embedding OK, shape: (1, 128)\n",
            "  mean distance: 0.07425883179530501\n",
            "  RESULT: NOT YOU\n",
            "\n",
            "Processing: input_image.jpg\n",
            "  preprocess OK, shape: (1, 100, 100, 3)\n",
            "  embedding OK, shape: (1, 128)\n",
            "  mean distance: 0.15967688585321108\n",
            "  RESULT: NOT YOU\n",
            "\n",
            "Processing: gettyimages-2218379589-612x612.jpg\n",
            "  preprocess OK, shape: (1, 100, 100, 3)\n",
            "  embedding OK, shape: (1, 128)\n",
            "  mean distance: 0.1989547312259674\n",
            "  RESULT: NOT YOU\n",
            "\n",
            "Processing: 20260116_090914_030.jpg\n",
            "  preprocess OK, shape: (1, 100, 100, 3)\n",
            "  embedding OK, shape: (1, 128)\n",
            "  mean distance: 0.04400862823240459\n",
            "  RESULT: YOU\n",
            "\n",
            "Processing: 20260116_090914_007.jpg\n",
            "  preprocess OK, shape: (1, 100, 100, 3)\n",
            "  embedding OK, shape: (1, 128)\n",
            "  mean distance: 0.03687350001807014\n",
            "  RESULT: YOU\n",
            "\n",
            "Processing: 20260116_091724_002.jpg\n",
            "  preprocess OK, shape: (1, 100, 100, 3)\n",
            "  embedding OK, shape: (1, 128)\n",
            "  mean distance: 0.02665379100168745\n",
            "  RESULT: YOU\n",
            "\n",
            "Processing: licensed-image (2).jpg\n",
            "  preprocess OK, shape: (1, 100, 100, 3)\n",
            "  embedding OK, shape: (1, 128)\n",
            "  mean distance: 0.1060162540525198\n",
            "  RESULT: NOT YOU\n",
            "\n",
            "Processing: licensed-image (1).jpg\n",
            "  preprocess OK, shape: (1, 100, 100, 3)\n",
            "  embedding OK, shape: (1, 128)\n",
            "  mean distance: 0.15684009219209352\n",
            "  RESULT: NOT YOU\n",
            "\n",
            "Processing: 20260116_091724_025.jpg\n",
            "  preprocess OK, shape: (1, 100, 100, 3)\n",
            "  embedding OK, shape: (1, 128)\n",
            "  mean distance: 0.027257324196398258\n",
            "  RESULT: YOU\n",
            "\n",
            "Processing: 20260116_091809_002.jpg\n",
            "  preprocess OK, shape: (1, 100, 100, 3)\n",
            "  embedding OK, shape: (1, 128)\n",
            "  mean distance: 0.034933927080904446\n",
            "  RESULT: YOU\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "AttributeError",
          "evalue": "'NoneType' object has no attribute 'items'",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
            "\u001b[0;32m/tmp/ipython-input-2168272023.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     12\u001b[0m )\n\u001b[1;32m     13\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 14\u001b[0;31m \u001b[0;32mfor\u001b[0m \u001b[0mimg\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mres\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mresults\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitems\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     15\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimg\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"→\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mres\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mAttributeError\u001b[0m: 'NoneType' object has no attribute 'items'"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Save weights\n",
        "siamese_model.save('siamesemodel_with_mean_distance.keras')"
      ],
      "metadata": {
        "id": "E4o4WB9KDoyb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "uyr4Rr1yTny1"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}